{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-10T13:58:41.322389Z",
     "start_time": "2024-03-10T13:58:38.875345Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv2d, MaxPool2d, Linear, Flatten\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import L1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10('CIFAR', False, transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T13:58:50.738979Z",
     "start_time": "2024-03-10T13:58:50.190194Z"
    }
   },
   "id": "e94d646e6945cadc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "CIFARModel(\n  (conv_maxp): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (mlp): Sequential(\n    (0): Linear(in_features=1024, out_features=64, bias=True)\n    (1): Linear(in_features=64, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " class CIFARModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_maxp = nn.Sequential(\n",
    "            Conv2d(3, 32, 5, padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(32, 32, 5, padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(32, 64, 5, padding=2),\n",
    "            MaxPool2d(2),\n",
    "        )\n",
    "        self.flatten = Flatten()\n",
    "        self.mlp = nn.Sequential(\n",
    "            Linear(1024, 64),\n",
    "            Linear(64, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_maxp(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "model = CIFARModel()\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T13:58:51.806396Z",
     "start_time": "2024-03-10T13:58:51.770772Z"
    }
   },
   "id": "7d90f5dd6412a7d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# debug model\n",
    "input = torch.ones((64, 3, 32, 32))\n",
    "output = model(input)\n",
    "input, output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f281afe6d6295ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#visualize model\n",
    "writer = SummaryWriter('logs')\n",
    "writer.add_graph(model, torch.ones((64, 3, 32, 32)))\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27cbe6252d445ec2"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:41<00:00,  8.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loss_CE = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "for epoch in tqdm(range(5)):  \n",
    "    for step, data in enumerate(dataloader):\n",
    "        imgs, targets = data\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_CE(outputs, targets)\n",
    "        writer.add_scalar('CIFAR_loss_CE', loss, step)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T14:28:41.594784Z",
     "start_time": "2024-03-10T14:28:00.437584Z"
    }
   },
   "id": "943b4282586a24fd"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([3, 1, 1, 0, 6, 6, 1, 6, 3, 1, 0, 9, 3, 7, 9, 0, 5, 2, 8, 6, 7, 0, 2, 9,\n",
      "        4, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 3, 4, 1, 9, 5, 8, 6, 5, 6, 0, 9, 3, 7,\n",
      "        4, 6, 9, 8, 2, 3, 8, 8, 7, 8, 2, 3, 7, 3, 6, 3])\n",
      "tar:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
      "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
      "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3])\n",
      "loss:  tensor(0.6522, grad_fn=<NllLossBackward0>)\n",
      "out: tensor([6, 6, 1, 0, 3, 7, 0, 6, 8, 8, 9, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 2, 2, 8,\n",
      "        8, 9, 0, 3, 8, 6, 4, 6, 6, 2, 0, 7, 4, 5, 6, 3, 1, 1, 2, 6, 7, 7, 4, 0,\n",
      "        6, 2, 1, 3, 0, 4, 3, 7, 8, 3, 1, 2, 8, 2, 0, 5])\n",
      "tar:  tensor([6, 2, 1, 2, 3, 7, 2, 6, 8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7,\n",
      "        8, 9, 0, 3, 8, 6, 4, 6, 6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7, 4, 0,\n",
      "        6, 2, 1, 3, 0, 4, 2, 7, 8, 3, 1, 2, 8, 0, 8, 3])\n",
      "loss:  tensor(0.5986, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    " for step, data in enumerate(dataloader):\n",
    "    if step > 1:\n",
    "        break\n",
    "    imgs, targets = data\n",
    "    outputs = model(imgs)\n",
    "    loss = loss_CE(outputs, targets)\n",
    "    print('out:', torch.argmax(outputs, 1))\n",
    "    print('tar: ', targets)\n",
    "    print('loss: ', loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T14:28:50.174795Z",
     "start_time": "2024-03-10T14:28:50.078018Z"
    }
   },
   "id": "9afee93fa3f09a4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "70b1aa4a439035d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
